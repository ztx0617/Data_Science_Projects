{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tianxing Zhai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "District of Columbia, U.S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://download.geofabrik.de/north-america/us/district-of-columbia-latest.osm.bz2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://download.geofabrik.de/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I selected this area beacuse that District of Columbia is the smallest state and the capital of America."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1. Data wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Transformation of data, from xml to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to parse the xml and transform useful data from xml to csv. In the pratice, the tutor cleaned the data before transformtion. It is time consuming because every cleaning step is a traversal of a large xml file. So I decide to transform data first, and clean the data using Pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below is my code of transformtion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "The process for this transformation is as follows:\n",
    "- Use iterparse to iteratively step through each top level element in the XML\n",
    "- Shape each element into several data structures using a custom function\n",
    "- Write each data structure to the appropriate .csv files\n",
    "\n",
    "The \"node\" field will hold a dictionary of the following top level node attributes:\n",
    "- id\n",
    "- version\n",
    "- lat\n",
    "- lon\n",
    "- timestamp\n",
    "- changeset\n",
    "\n",
    "The \"node_tags\" field will hold a list of dictionaries, one per secondary tag. Secondary tags are\n",
    "child tags of node which have the tag name/type: \"tag\". Each dictionary should have the following\n",
    "fields from the secondary tag attributes:\n",
    "- id: the top level node id attribute value\n",
    "- key: the full tag \"k\" attribute value if no colon is present or the characters after the colon if one is.\n",
    "- value: the tag \"v\" attribute value\n",
    "- type: either the characters before the colon in the tag \"k\" value or \"regular\" if a colon\n",
    "        is not present.\n",
    "\n",
    "Additionally,\n",
    "\n",
    "- if the tag \"k\" value contains a \":\" the characters before the \":\" will be set as the tag type\n",
    "  and characters after the \":\" will be set as the tag key\n",
    "- if there are additional \":\" in the \"k\" value they and they will be ignored and kept as part of\n",
    "  the tag key. For example:\n",
    "\n",
    "  <tag k=\"addr:street:name\" v=\"Lincoln\"/>\n",
    "  will be turned into\n",
    "  {'id': 12345, 'key': 'street:name', 'value': 'Lincoln', 'type': 'addr'}\n",
    "\n",
    "- If a node has no secondary tags then the \"node_tags\" field will just contain an empty list.\n",
    "\n",
    "The final return value for a \"node\" element will look something like:\n",
    "\n",
    "{'node': {'id': 757860928,\n",
    "          'version': '2',\n",
    "          'lat': 41.9747374,\n",
    "          'lon': -87.6920102,\n",
    "          'timestamp': '2010-07-22T16:16:51Z',\n",
    "      'changeset': 5288876},\n",
    " 'node_tags': [{'id': 757860928,\n",
    "                'key': 'amenity',\n",
    "                'value': 'fast_food',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'cuisine',\n",
    "                'value': 'sausage',\n",
    "                'type': 'regular'},\n",
    "               {'id': 757860928,\n",
    "                'key': 'name',\n",
    "                'value': \"Shelly's Tasty Freeze\",\n",
    "                'type': 'regular'}]}\n",
    "\n",
    "### If the element top level tag is \"way\":\n",
    "The dictionary will have the format {\"way\": ..., \"way_tags\": ..., \"way_nodes\": ...}\n",
    "\n",
    "The \"way\" field should hold a dictionary of the following top level way attributes:\n",
    "- id\n",
    "- version\n",
    "- timestamp\n",
    "- changeset\n",
    "\n",
    "\n",
    "The \"way_tags\" field will again hold a list of dictionaries, following the exact same rules as\n",
    "for \"node_tags\".\n",
    "\n",
    "Additionally, the dictionary should have a field \"way_nodes\". \"way_nodes\" will hold a list of\n",
    "dictionaries, one for each nd child tag.  Each dictionary will have the fields:\n",
    "- id: the top level element (way) id\n",
    "- node_id: the ref attribute value of the nd tag\n",
    "- position: the index starting at 0 of the nd tag i.e. what order the nd tag appears within\n",
    "            the way element\n",
    "\n",
    "The final return value for a \"way\" element will look something like:\n",
    "\n",
    "{'way': {'id': 209809850,\n",
    "         'version': '1',\n",
    "         'timestamp': '2013-03-13T15:58:04Z',\n",
    "         'changeset': 15353317},\n",
    " 'way_nodes': [{'id': 209809850, 'node_id': 2199822281, 'position': 0},\n",
    "               {'id': 209809850, 'node_id': 2199822390, 'position': 1},\n",
    "               {'id': 209809850, 'node_id': 2199822392, 'position': 2},\n",
    "               {'id': 209809850, 'node_id': 2199822369, 'position': 3},\n",
    "               {'id': 209809850, 'node_id': 2199822370, 'position': 4},\n",
    "               {'id': 209809850, 'node_id': 2199822284, 'position': 5},\n",
    "               {'id': 209809850, 'node_id': 2199822281, 'position': 6}],\n",
    " 'way_tags': [{'id': 209809850,\n",
    "               'key': 'housenumber',\n",
    "               'type': 'addr',\n",
    "               'value': '1412'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street',\n",
    "               'type': 'addr',\n",
    "               'value': 'West Lexington St.'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:name',\n",
    "               'type': 'addr',\n",
    "               'value': 'Lexington'},\n",
    "              {'id': '209809850',\n",
    "               'key': 'street:prefix',\n",
    "               'type': 'addr',\n",
    "               'value': 'West'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'street:type',\n",
    "               'type': 'addr',\n",
    "               'value': 'Street'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building',\n",
    "               'type': 'regular',\n",
    "               'value': 'yes'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'levels',\n",
    "               'type': 'building',\n",
    "               'value': '1'},\n",
    "              {'id': 209809850,\n",
    "               'key': 'building_id',\n",
    "               'type': 'chicago',\n",
    "               'value': '366409'}]}\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import codecs\n",
    "import re\n",
    "import xml.etree.cElementTree as ET\n",
    "\n",
    "OSM_PATH = \"district-of-columbia-latest.osm\"\n",
    "\n",
    "NODES_PATH = \"nodes.csv\"\n",
    "NODE_TAGS_PATH = \"nodes_tags.csv\"\n",
    "WAYS_PATH = \"ways.csv\"\n",
    "WAY_NODES_PATH = \"ways_nodes.csv\"\n",
    "WAY_TAGS_PATH = \"ways_tags.csv\"\n",
    "\n",
    "\n",
    "NODE_FIELDS = ['id', 'lat', 'lon', 'version', 'changeset', 'timestamp']\n",
    "NODE_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_FIELDS = ['id', 'version', 'changeset', 'timestamp']\n",
    "WAY_TAGS_FIELDS = ['id', 'key', 'value', 'type']\n",
    "WAY_NODES_FIELDS = ['id', 'node_id', 'position']\n",
    "\n",
    "\n",
    "def shape_element(element):\n",
    "    \"\"\"Clean and shape node or way XML element to Python dict\"\"\"\n",
    "\n",
    "    node_attribs = {}\n",
    "    way_attribs = {}\n",
    "    way_nodes = []\n",
    "    tags = [] # Handle secondary tags the same way for both node and way elements\n",
    "\n",
    "    \n",
    "    if element.tag == 'node':\n",
    "        \n",
    "        node_attribs = element.attrib\n",
    "        node_attribs['id'] = int(node_attribs['id'])\n",
    "        node_attribs['lat'] = float(node_attribs['lat'])\n",
    "        node_attribs['lon'] = float(node_attribs['lon'])\n",
    "        node_attribs['changeset'] = int(node_attribs['changeset'])\n",
    "        \n",
    "        for tag in element.iter(\"tag\"):\n",
    "            \n",
    "            tag_attribs = {}\n",
    "            \n",
    "            tag_attribs['id'] =  node_attribs['id']\n",
    "            tag_attribs['value'] = tag.attrib['v']\n",
    "                \n",
    "            if ':' in tag.attrib['k']:\n",
    "                temp1 = re.split(':',tag.attrib['k'])\n",
    "                if len(temp1) == 2:\n",
    "                    tag_attribs['type'] = temp1[0]\n",
    "                    tag_attribs['key'] = temp1[1]\n",
    "                else:\n",
    "                    tag_attribs['type'] = temp1[0]\n",
    "                    tag_attribs['key'] = ':'.join(temp1[1:])\n",
    "            else:\n",
    "                tag_attribs['type'] = 'regular'\n",
    "                tag_attribs['key'] = tag.attrib['k']\n",
    "                \n",
    "            tags.append(tag_attribs)\n",
    "            \n",
    "        return {'node': node_attribs, 'node_tags': tags}\n",
    "    \n",
    "    elif element.tag == 'way':\n",
    "        \n",
    "        way_attribs = element.attrib\n",
    "        way_attribs['id'] = int(way_attribs['id'])\n",
    "        way_attribs['changeset'] = int(way_attribs['changeset'])\n",
    "        i = 0\n",
    "        \n",
    "        for tag in element.iter(\"tag\"):\n",
    "            \n",
    "            tag_attribs = {}\n",
    "            \n",
    "            tag_attribs['id'] =  way_attribs['id']\n",
    "            tag_attribs['value'] = tag.attrib['v']\n",
    "                \n",
    "            if ':' in tag.attrib['k']:\n",
    "                temp1 = re.split(':',tag.attrib['k'])\n",
    "                if len(temp1) == 2:\n",
    "                    tag_attribs['type'] = temp1[0]\n",
    "                    tag_attribs['key'] = temp1[1]\n",
    "                else:\n",
    "                    tag_attribs['type'] = temp1[0]\n",
    "                    tag_attribs['key'] = ':'.join(temp1[1:])\n",
    "            else:\n",
    "                tag_attribs['type'] = 'regular'\n",
    "                tag_attribs['key'] = tag.attrib['k']\n",
    "                \n",
    "            tags.append(tag_attribs)\n",
    "            \n",
    "        for nd in element.iter(\"nd\"):\n",
    "                \n",
    "            nd_attribs = {}\n",
    "                \n",
    "            nd_attribs['id'] =  way_attribs['id']\n",
    "            nd_attribs['node_id'] = int(nd.attrib['ref'])\n",
    "            nd_attribs['position'] = i\n",
    "            i += 1\n",
    "            way_nodes.append(nd_attribs)\n",
    "        \n",
    "        return {'way': way_attribs, 'way_nodes': way_nodes, 'way_tags': tags}\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Helper Functions                     #\n",
    "# ================================================== #\n",
    "def get_element(osm_file, tags=('node', 'way', 'relation')):\n",
    "    \"\"\"Yield element if it is the right type of tag\"\"\"\n",
    "    osm_file = open(osm_file,'r',encoding='utf-8')\n",
    "    context = ET.iterparse(osm_file, events=('start', 'end'))\n",
    "    _, root = next(context)\n",
    "    for event, elem in context:\n",
    "        if event == 'end' and elem.tag in tags:\n",
    "            yield elem\n",
    "            root.clear()\n",
    "\n",
    "\n",
    "class MyDictWriter(csv.DictWriter, object):\n",
    "    \"\"\"Write the data to csv files (Becuase Python3 uses utf-8, conversion of unicode is no longer needed)\"\"\"\n",
    "    def writerow(self, row):\n",
    "        super(MyDictWriter, self).writerow({\n",
    "            k: v for k, v in row.items()\n",
    "        })\n",
    "\n",
    "    def writerows(self, rows):\n",
    "        for row in rows:\n",
    "            self.writerow(row)\n",
    "\n",
    "\n",
    "# ================================================== #\n",
    "#               Main Function                        #\n",
    "# ================================================== #\n",
    "def process_map(file_in):\n",
    "    \"\"\"Iteratively process each XML element and write to csv(s)\"\"\"\n",
    "\n",
    "    with codecs.open(NODES_PATH, 'w', encoding='utf-8') as nodes_file, \\\n",
    "         codecs.open(NODE_TAGS_PATH, 'w', encoding='utf-8') as nodes_tags_file, \\\n",
    "         codecs.open(WAYS_PATH, 'w', encoding='utf-8') as ways_file, \\\n",
    "         codecs.open(WAY_NODES_PATH, 'w', encoding='utf-8') as way_nodes_file, \\\n",
    "         codecs.open(WAY_TAGS_PATH, 'w', encoding='utf-8') as way_tags_file:\n",
    "\n",
    "        nodes_writer = MyDictWriter(nodes_file, NODE_FIELDS)\n",
    "        node_tags_writer = MyDictWriter(nodes_tags_file, NODE_TAGS_FIELDS)\n",
    "        ways_writer = MyDictWriter(ways_file, WAY_FIELDS)\n",
    "        way_nodes_writer = MyDictWriter(way_nodes_file, WAY_NODES_FIELDS)\n",
    "        way_tags_writer = MyDictWriter(way_tags_file, WAY_TAGS_FIELDS)\n",
    "\n",
    "        nodes_writer.writeheader()\n",
    "        node_tags_writer.writeheader()\n",
    "        ways_writer.writeheader()\n",
    "        way_nodes_writer.writeheader()\n",
    "        way_tags_writer.writeheader()\n",
    "\n",
    "        for element in get_element(file_in, tags=('node', 'way')):\n",
    "            el = shape_element(element)\n",
    "            if el:\n",
    "                if element.tag == 'node':\n",
    "                    nodes_writer.writerow(el['node'])\n",
    "                    node_tags_writer.writerows(el['node_tags'])\n",
    "                elif element.tag == 'way':\n",
    "                    ways_writer.writerow(el['way'])\n",
    "                    way_nodes_writer.writerows(el['way_nodes'])\n",
    "                    way_tags_writer.writerows(el['way_tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_map(OSM_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Cleaning of data, from csv to pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# open the data as pandas dataframe\n",
    "nodes = pd.read_csv('nodes.csv')\n",
    "nodes_tags = pd.read_csv('nodes_tags.csv')\n",
    "ways = pd.read_csv('ways.csv')\n",
    "ways_nodes = pd.read_csv('ways_nodes.csv')\n",
    "ways_tags = pd.read_csv('ways_tags.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2.1. Dealing with problematic characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define [=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n] as problematic characters. Keys which contains these characters are probably problematic. I try to find these information using Pandas which is much faster than the iteration method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_problemchars (x):\n",
    "    x = str(x)\n",
    "    problemchars = re.compile(r'.*[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n].*')\n",
    "    if re.match(problemchars, x):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "problemchars_bool_ways = ways_tags['key'].apply(find_problemchars)\n",
    "problemchars_bool_nodes = nodes_tags['key'].apply(find_problemchars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [id, key, value, type]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_tags[problemchars_bool_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424280</th>\n",
       "      <td>67069962</td>\n",
       "      <td>citybikes.com</td>\n",
       "      <td>4</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id            key value     type\n",
       "424280  67069962  citybikes.com     4  regular"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ways_tags[problemchars_bool_ways]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no problematic characters in keys of node tags. There is only one problematic character in keys of way tags. To decide how to deal with this key, we need to know all attributes of the way with id 67069962. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>key</th>\n",
       "      <th>value</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>424273</th>\n",
       "      <td>67069962</td>\n",
       "      <td>source</td>\n",
       "      <td>dcgis</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424274</th>\n",
       "      <td>67069962</td>\n",
       "      <td>dataset</td>\n",
       "      <td>buildings</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424275</th>\n",
       "      <td>67069962</td>\n",
       "      <td>building</td>\n",
       "      <td>yes</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424276</th>\n",
       "      <td>67069962</td>\n",
       "      <td>lot</td>\n",
       "      <td>0802</td>\n",
       "      <td>dcgis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424277</th>\n",
       "      <td>67069962</td>\n",
       "      <td>street</td>\n",
       "      <td>Columbia Road Northwest</td>\n",
       "      <td>addr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424278</th>\n",
       "      <td>67069962</td>\n",
       "      <td>gis_id</td>\n",
       "      <td>103264</td>\n",
       "      <td>dcgis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424279</th>\n",
       "      <td>67069962</td>\n",
       "      <td>square</td>\n",
       "      <td>2564</td>\n",
       "      <td>dcgis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424280</th>\n",
       "      <td>67069962</td>\n",
       "      <td>citybikes.com</td>\n",
       "      <td>4</td>\n",
       "      <td>regular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424281</th>\n",
       "      <td>67069962</td>\n",
       "      <td>housenumber</td>\n",
       "      <td>1772</td>\n",
       "      <td>addr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424282</th>\n",
       "      <td>67069962</td>\n",
       "      <td>captureyear</td>\n",
       "      <td>19990331</td>\n",
       "      <td>dcgis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id            key                    value     type\n",
       "424273  67069962         source                    dcgis  regular\n",
       "424274  67069962        dataset                buildings  regular\n",
       "424275  67069962       building                      yes  regular\n",
       "424276  67069962            lot                     0802    dcgis\n",
       "424277  67069962         street  Columbia Road Northwest     addr\n",
       "424278  67069962         gis_id                   103264    dcgis\n",
       "424279  67069962         square                     2564    dcgis\n",
       "424280  67069962  citybikes.com                        4  regular\n",
       "424281  67069962    housenumber                     1772     addr\n",
       "424282  67069962    captureyear                 19990331    dcgis"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ways_tags.loc[ways_tags['id'] == 67069962]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the way 67069962 seems describe a building. One of the key is 'citybikes.com', a website, and the value of that key is 4. It is hard to decide whether to delete it or not because we don't know the relationship between that building and 'citybikes.com'. To be cautious, I decide to keep that row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2.2 Dealing with street names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \"Trail\", \"Parkway\", \"Commons\"] are commly used street names. We regard these as 'expected' words and try to find street names end with 'unexpected' words, which might be problematic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to find  'unexpected' end words in street names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_street (x):\n",
    "    expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "                \"Trail\", \"Parkway\", \"Commons\"]\n",
    "    x = str(x)\n",
    "    x = x.split()[-1]\n",
    "    if x in expected:\n",
    "        return 'expected'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def run_audit (data, function):\n",
    "    return (data.loc[(data['type'] == 'addr') & (data['key'] == 'street')]['value']\n",
    "            .apply(function)\n",
    "            .value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Unexpected' end words in ways_tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Northwest     56886\n",
       "Northeast     34509\n",
       "Southeast     23569\n",
       "Southwest      2274\n",
       "NW               48\n",
       "SW               48\n",
       "SE               46\n",
       "expected         30\n",
       "NE                9\n",
       "road)             4\n",
       "North             2\n",
       "3456              2\n",
       "Ave               1\n",
       "Highway           1\n",
       "Southeast\\        1\n",
       "Plaza             1\n",
       "S.W.              1\n",
       "850               1\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_audit (ways_tags, audit_street)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Unexpected' end words in ways_tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Northwest    8219\n",
       "Southeast    5236\n",
       "Northeast    4783\n",
       "Southwest    1438\n",
       "NW             51\n",
       "SW             31\n",
       "NE             31\n",
       "SE             30\n",
       "expected       15\n",
       "Alley           2\n",
       "BN              2\n",
       "Floor           2\n",
       "1               2\n",
       "Hill            1\n",
       "Mall            1\n",
       "avenue          1\n",
       "20019           1\n",
       "George          1\n",
       "northwest       1\n",
       "300             1\n",
       "West            1\n",
       "328             1\n",
       "n.w.            1\n",
       "Bottom          1\n",
       "N.W.            1\n",
       "St.)            1\n",
       "floor           1\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_audit (nodes_tags, audit_street)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 45 'expected' words in the two data sets. Most of street names end with \"Northwest\", \"Southeast\", \"Northeast\", \"Southwest\" and their abbreviations. This seems the naming rule of Washington D.C.. Besides, few names end with \"North\", \"West\", \"Alley\" and \"Mall\". These names should also be considered as normal words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I alter the code to recognize new expected normal end words and expand some abbreviations (like \"SW\" to \"Southwest\"). After that, find the full street names with unexpected end words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_street_new (x):\n",
    "    \n",
    "    # add \"Northwest\", \"Southeast\", \"Northeast\",\"Southwest\",\"North\", \"Alley\", \"Mall\", \"West\" to expected words\n",
    "    expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "                \"Trail\", \"Parkway\", \"Commons\", \"Northwest\", \"Southeast\", \"Northeast\",\"Southwest\",\n",
    "                \"North\", \"Alley\", \"Mall\", \"West\"]\n",
    "    # expand some abbreviations\n",
    "    correction = {'NW': 'Northwest',\n",
    "             'SW': 'Southwest',\n",
    "             'NE': 'Northeast',\n",
    "             'SE': 'Southeast',\n",
    "             'Ave': 'Avenue',\n",
    "             'Southeast\\\\': 'Southeast',\n",
    "             'S.W.': 'Southwest',\n",
    "             'N.W.': 'Northwest',\n",
    "             'avenue': 'Avenue',\n",
    "             'northwest': 'Northwest',\n",
    "             'n.w.': 'Northwest'}\n",
    "    \n",
    "    t = str(x)\n",
    "    t = t.split()[-1]\n",
    "    \n",
    "    if t in correction:\n",
    "        t = correction[t]\n",
    "    if t in expected:\n",
    "        return 'normal'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal                                    117424\n",
       "K Street NW (access road)                      4\n",
       "3456                                           2\n",
       "Connecticut Avenue Northwest Suite 850         1\n",
       "Canal Center Plaza                             1\n",
       "Lee Highway                                    1\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_audit (ways_tags, audit_street_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal                                        19842\n",
       "North Capitol Street BN                           2\n",
       "1                                                 2\n",
       "Calvert Street Northwest 2nd Floor                1\n",
       "M Street Northwest, Suite 328                     1\n",
       "5601 E Capitol St SE, Washington, DC 20019        1\n",
       "Wisconsin Ave (on Jenifer St.)                    1\n",
       "17th St NW, 9th floor                             1\n",
       "13rd Avenue Prince George                         1\n",
       "Connecticut Ave NW 2nd Floor                      1\n",
       "Capitol Hill                                      1\n",
       "K Street NW Suite 300                             1\n",
       "23rd St NW ,Foggy Bottom                          1\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_audit (nodes_tags, audit_street_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the correction above, there are still some abnormal names which only appear once or twice. I have to fix them case by case using the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_street_name (x):\n",
    "    \n",
    "    # add \"Northwest\", \"Southeast\", \"Northeast\",\"Southwest\",\"North\", \"Alley\", \"Mall\", \"West\"to expected words\n",
    "    expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "                \"Trail\", \"Parkway\", \"Commons\", \"Northwest\", \"Southeast\", \"Northeast\",\"Southwest\",\n",
    "                \"North\", \"Alley\", \"Mall\", \"West\"]\n",
    "    # expand some abbreviations\n",
    "    correction = {'NW': 'Northwest',\n",
    "             'SW': 'Southwest',\n",
    "             'NE': 'Northeast',\n",
    "             'SE': 'Southeast',\n",
    "             'Ave': 'Avenue',\n",
    "             'Southeast\\\\': 'Southeast',\n",
    "             'S.W.': 'Southwest',\n",
    "             'N.W.': 'Northwest',\n",
    "             'avenue': 'Avenue',\n",
    "             'northwest': 'Northwest',\n",
    "             'n.w.': 'Northwest',\n",
    "             'St': 'Street'}\n",
    "    \n",
    "    x = str(x)\n",
    "    \n",
    "    if x.isdigit():\n",
    "        print (x + ' is labeled as abnormal value')\n",
    "        return 'Abnormal value' # fix wrong street name with only digit, label them as abnormal value\n",
    "    else:\n",
    "        if ',' in x:\n",
    "            x = x.split(',')[0] # fix wrong street name with comma\n",
    "        if '(' in x:\n",
    "            x = x.split(' (')[0] # fix wrong street name with parenthesis\n",
    "        \n",
    "        tlist = x.split()\n",
    "        t = tlist[-1]\n",
    "        \n",
    "        if t.isdigit():\n",
    "            x = ' '.join(tlist[:-2]) # fix wrong street name like 'Connecticut Avenue Northwest Suite 850 '\n",
    "            tlist = x.split()\n",
    "            t = tlist[-1]\n",
    "        if t == 'Floor':\n",
    "            x = ' '.join(tlist[:-2]) # fix the wrong street name 'Connecticut Ave NW 2nd Floor'\n",
    "            tlist = x.split()\n",
    "            t = tlist[-1]\n",
    "        if t in correction:\n",
    "            t = correction[t] # fix wrong street name with abbreviation\n",
    "            tlist[-1] = t\n",
    "            x = ' '.join(tlist)\n",
    "        if t in expected:\n",
    "            return x\n",
    "        else:\n",
    "            print (x + ' is labeled as abnormal value')\n",
    "            return 'Abnormal value' # fix wrong street name like 'Canal Center Plaza', label them as abnormal value\n",
    "\n",
    "def update (data):\n",
    "    street_new = (data.loc[(data['type'] == 'addr') & (data['key'] == 'street')]['value']\n",
    "                .apply(fix_street_name))\n",
    "    data.update(street_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 is labeled as abnormal value\n",
      "1 is labeled as abnormal value\n",
      "North Capitol Street BN is labeled as abnormal value\n",
      "North Capitol Street BN is labeled as abnormal value\n",
      "Capitol Hill is labeled as abnormal value\n",
      "13rd Avenue Prince George is labeled as abnormal value\n"
     ]
    }
   ],
   "source": [
    "update (nodes_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canal Center Plaza is labeled as abnormal value\n",
      "Lee Highway is labeled as abnormal value\n",
      "3456 is labeled as abnormal value\n",
      "3456 is labeled as abnormal value\n"
     ]
    }
   ],
   "source": [
    "update (ways_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning the street names, I run the audit program again to test the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Northwest    8273\n",
       "Southeast    5266\n",
       "Northeast    4814\n",
       "Southwest    1468\n",
       "expected       25\n",
       "value           6\n",
       "Alley           2\n",
       "West            1\n",
       "Mall            1\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_audit (nodes_tags, audit_street)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Northwest    56939\n",
       "Northeast    34518\n",
       "Southeast    23615\n",
       "Southwest     2322\n",
       "expected        33\n",
       "value            4\n",
       "North            2\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_audit (ways_tags, audit_street)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are no unexpected names anymore. The cleaning step successfully finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2.3 Dealing with postcodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard postcodes of Washington D.C. should have five digits and in the range from 20001 to 20600. Here is how I audit postcodes and find abnormal vaues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audit_postcode (x):\n",
    "    x = str(x)\n",
    "    if (len(x) != 5) | (not x.isdigit()):\n",
    "        return x\n",
    "    elif int(x) not in range(20001, 20600):\n",
    "        return x\n",
    "    else:\n",
    "        return 'normal'\n",
    "    \n",
    "def run_audit (data):\n",
    "    return (data.loc[data['key'] == 'postcode']['value']\n",
    "            .apply(audit_postcode)\n",
    "            .value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        61991\n",
       "20910             6\n",
       "20912             1\n",
       "20020-4706        1\n",
       "20005-1015        1\n",
       "22207             1\n",
       "20005-7700        1\n",
       "20016-2137        1\n",
       "20005-1009        1\n",
       "20005-1001        1\n",
       "22209             1\n",
       "20005-1019        1\n",
       "22101             1\n",
       "20005-1013        1\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_audit (ways_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal        9424\n",
       "DC 20002         1\n",
       "20006-5346       1\n",
       "20005-4111       1\n",
       "2005             1\n",
       "20743            1\n",
       "20036-5305       1\n",
       "2011             1\n",
       "20005-1015       1\n",
       "22314            1\n",
       "20009-5540       1\n",
       "20005-5702       1\n",
       "Name: value, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_audit (nodes_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There four types abnormal values: 1. Postcodes with '-' (like 20006-5346). The numbers after '-' make postcodes more precise, but also make them not fit the format of most postcodes. For these postcodes, I will only keep the first five digits. 2. Postcode with 'DC' (DC 20002). For this postcode, I will only keep the digits. 3. Abnormal postcodes like 2005 and 2011, which are meaningless. I will label them as 'Abnormal value'. 4. Postcodes out of range (20001-20600). These are all postcodes of nearby cities. For example, 20910 is the postcode of Silver Spring, a city borders on Washington on the north. It is acceptable that the postcode data of Washington have few values come from neighboring cities, beacuse there are no remarkable boundaries between them. Therefore, I will keep these values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are my codes of fixing postcodes and updating the orginal data sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_postcode (x):\n",
    "    x = str(x)\n",
    "    if '-' in x:\n",
    "        x = x.split('-')[0] # fix postcode like '20005-1015'\n",
    "    if 'DC' in x:\n",
    "        x = x.split()[1] # fix the postcode 'DC 20002'\n",
    "    if len(x) == 5:\n",
    "        return x\n",
    "    else:\n",
    "        print (x + ' is labeled as abnormal value') # 2011 and 2005 will be labeled as 'Abnormal value'\n",
    "        return 'Abnormal value' \n",
    "\n",
    "def run_fix (data):\n",
    "    postcodes_new = data.loc[data['key'] == 'postcode']['value'].apply(fix_postcode)\n",
    "    data.update(postcodes_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_fix (ways_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2011 is labeled as abnormal value\n",
      "2005 is labeled as abnormal value\n"
     ]
    }
   ],
   "source": [
    "run_fix (nodes_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Export of data, from pandas dataframe to SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finishing all the cleaning steps, the next step is to export the cleaned data from pandas dataframe to SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing to do is to creat five SQL tables with correct data types and references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('Washington.db')\n",
    "c = conn.cursor()\n",
    "c.execute('''    \n",
    "    CREATE TABLE nodes (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    lat REAL,\n",
    "    lon REAL,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT)\n",
    "    ''')\n",
    "c.execute('''    \n",
    "    CREATE TABLE nodes_tags (\n",
    "    id INTEGER,\n",
    "    key TEXT,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES nodes(id))\n",
    "    ''')\n",
    "c.execute('''    \n",
    "    CREATE TABLE ways (\n",
    "    id INTEGER PRIMARY KEY NOT NULL,\n",
    "    version INTEGER,\n",
    "    changeset INTEGER,\n",
    "    timestamp TEXT)\n",
    "    ''')\n",
    "c.execute('''    \n",
    "    CREATE TABLE ways_tags (\n",
    "    id INTEGER NOT NULL,\n",
    "    key TEXT NOT NULL,\n",
    "    value TEXT,\n",
    "    type TEXT,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id))\n",
    "    ''')\n",
    "c.execute('''    \n",
    "    CREATE TABLE ways_nodes (\n",
    "    id INTEGER NOT NULL,\n",
    "    node_id INTEGER NOT NULL,\n",
    "    position INTEGER NOT NULL,\n",
    "    FOREIGN KEY (id) REFERENCES ways(id),\n",
    "    FOREIGN KEY (node_id) REFERENCES nodes(id))\n",
    "    ''')\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then export data from pandas dataframes to corresponding SQL tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('Washington.db')\n",
    "for dataframe in ['nodes', 'nodes_tags', 'ways', 'ways_tags', 'ways_nodes']:\n",
    "    locals()[dataframe].to_sql(dataframe, conn, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2. The overview of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.The size of files "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "district-of-columbia-latest.osm ........ 316 MB                                             \n",
    "Washington.db ................................ 180 MB    \n",
    "nodes.csv ........................................ 95.7 MB   \n",
    "nodes_tags.csv ............................... 5.80 MB   \n",
    "ways.csv ......................................... 6.97 MB   \n",
    "ways_nodes.csv ............................. 45.9 MB   \n",
    "ways_tags.csv ................................ 43.1 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The amount of nodes and ways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the code to run a query and print results by row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('Washington.db')\n",
    "c = conn.cursor()\n",
    "\n",
    "def run_query (query):\n",
    "    result = c.execute(query)\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1699412,)\n"
     ]
    }
   ],
   "source": [
    "run_query ('SELECT COUNT(*) FROM nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The amount of ways:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(206289,)\n"
     ]
    }
   ],
   "source": [
    "run_query ('SELECT COUNT(*) FROM ways')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How many nodes and ways have tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41181,)\n"
     ]
    }
   ],
   "source": [
    "run_query ('SELECT COUNT(DISTINCT(id)) FROM nodes_tags') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202363,)\n"
     ]
    }
   ],
   "source": [
    "run_query ('SELECT COUNT(DISTINCT(id)) FROM ways_tags') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 41181 nodes have tags, amounted to only 2% of whole nodes. While there are 202363 ways have tags, amounted to 98% of whole ways. That means we can get better information from ways, not nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Which nodes/ways have most tags and how many tags do they have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TOP 10 ways which have most tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48268463, 55)\n",
      "(255331569, 55)\n",
      "(48207262, 54)\n",
      "(48207538, 54)\n",
      "(48207335, 53)\n",
      "(48207345, 53)\n",
      "(48207367, 51)\n",
      "(48268465, 51)\n",
      "(48207321, 50)\n",
      "(48207330, 50)\n"
     ]
    }
   ],
   "source": [
    "run_query ('SELECT id, COUNT(*) FROM ways_tags GROUP BY id ORDER BY count(*) DESC LIMIT 10') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TOP 10 nodes which have most tags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158368533, 149)\n",
      "(2507807432, 35)\n",
      "(367142763, 26)\n",
      "(1181385550, 24)\n",
      "(1181385554, 24)\n",
      "(1181385557, 24)\n",
      "(1181385567, 24)\n",
      "(1181385573, 24)\n",
      "(1181385584, 24)\n",
      "(1181385594, 24)\n"
     ]
    }
   ],
   "source": [
    "run_query ('SELECT id, COUNT(*) FROM nodes_tags GROUP BY id ORDER BY count(*) DESC LIMIT 10') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that ways with most tags have around 50+ tags and nodes with most tags around 20+ tags. However, there is an outlier: node id 158368533 has 149 tags! I need to find why."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print all tags that id 158368533 have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158368533, 'admin_level', '2', 'regular')\n",
      "(158368533, 'alt_name', 'Washington DC', 'regular')\n",
      "(158368533, 'alt_name_1', 'Washington, D.C.', 'regular')\n",
      "(158368533, 'vi', 'Oa-sinh-tn', 'alt_name')\n",
      "(158368533, 'capital', 'yes', 'regular')\n",
      "(158368533, 'population', '2010', 'census')\n",
      "(158368533, 'ele', '7', 'regular')\n",
      "(158368533, 'Class', 'Populated Place', 'gnis')\n",
      "(158368533, 'County', 'District of Columbia', 'gnis')\n",
      "(158368533, 'County_num', '001', 'gnis')\n",
      "(158368533, 'id', '531871', 'gnis')\n",
      "(158368533, 'ST_alpha', 'DC', 'gnis')\n",
      "(158368533, 'ST_num', '11', 'gnis')\n",
      "(158368533, 'int_name', 'Washington, D.C.', 'regular')\n",
      "(158368533, 'continent', 'North America', 'is_in')\n",
      "(158368533, 'country', 'United States', 'is_in')\n",
      "(158368533, 'country_code', 'US', 'is_in')\n",
      "(158368533, 'iso_3166_2', 'US-DC', 'is_in')\n",
      "(158368533, 'name', 'Washington', 'regular')\n",
      "(158368533, 'am', ' ', 'name')\n",
      "(158368533, 'an', 'Washington', 'name')\n",
      "(158368533, 'ang', 'Hsingatn', 'name')\n",
      "(158368533, 'ar', '', 'name')\n",
      "(158368533, 'arc', '', 'name')\n",
      "(158368533, 'arz', '', 'name')\n",
      "(158368533, 'ast', 'Washington DC', 'name')\n",
      "(158368533, 'ay', 'Washington, DC', 'name')\n",
      "(158368533, 'az', 'Vainqton', 'name')\n",
      "(158368533, 'bar', 'Washington', 'name')\n",
      "(158368533, 'bat-smg', 'Vaingtuons', 'name')\n",
      "(158368533, 'be', '', 'name')\n",
      "(158368533, 'be-tarask', '', 'name')\n",
      "(158368533, 'bn', '', 'name')\n",
      "(158368533, 'bo', '', 'name')\n",
      "(158368533, 'bpy', '  , ', 'name')\n",
      "(158368533, 'br', 'Washington D.C.', 'name')\n",
      "(158368533, 'ca', 'Washington DC', 'name')\n",
      "(158368533, 'cdo', 'Hu-sng-dung, D.C.', 'name')\n",
      "(158368533, 'ce', '', 'name')\n",
      "(158368533, 'chy', 'Vtano', 'name')\n",
      "(158368533, 'ckb', '  ', 'name')\n",
      "(158368533, 'co', 'Washington DC', 'name')\n",
      "(158368533, 'crh', 'Vaington', 'name')\n",
      "(158368533, 'cv', '', 'name')\n",
      "(158368533, 'da', 'Washington D.C.', 'name')\n",
      "(158368533, 'de', 'Washington D.C.', 'name')\n",
      "(158368533, 'diq', 'Washington D.C.', 'name')\n",
      "(158368533, 'el', '', 'name')\n",
      "(158368533, 'en', 'Washington D.C.', 'name')\n",
      "(158368533, 'eo', 'Vaingtono', 'name')\n",
      "(158368533, 'es', 'Washington D. C.', 'name')\n",
      "(158368533, 'et', 'Washington', 'name')\n",
      "(158368533, 'eu', 'Washington', 'name')\n",
      "(158368533, 'ext', 'Washington D.C.', 'name')\n",
      "(158368533, 'fa', '', 'name')\n",
      "(158368533, 'fi', 'Washington', 'name')\n",
      "(158368533, 'fiu-vro', 'Washington', 'name')\n",
      "(158368533, 'fo', 'Washington DC', 'name')\n",
      "(158368533, 'fr', 'Washington', 'name')\n",
      "(158368533, 'frp', 'Washington', 'name')\n",
      "(158368533, 'fy', 'Washington D.C.', 'name')\n",
      "(158368533, 'gn', 'Washington D.C.', 'name')\n",
      "(158368533, 'haw', 'Wakinekona', 'name')\n",
      "(158368533, 'he', '', 'name')\n",
      "(158368533, 'hr', 'Washington', 'name')\n",
      "(158368533, 'ht', 'Wachintn', 'name')\n",
      "(158368533, 'hu', 'Washington', 'name')\n",
      "(158368533, 'hy', '', 'name')\n",
      "(158368533, 'io', 'Washington DC', 'name')\n",
      "(158368533, 'is', 'Washington', 'name')\n",
      "(158368533, 'it', 'Washington', 'name')\n",
      "(158368533, 'ja', '', 'name')\n",
      "(158368533, 'ka', '', 'name')\n",
      "(158368533, 'kk', '', 'name')\n",
      "(158368533, 'kn', ', ..', 'name')\n",
      "(158368533, 'ko', '', 'name')\n",
      "(158368533, 'krc', '', 'name')\n",
      "(158368533, 'ku', 'Washington', 'name')\n",
      "(158368533, 'ky', '', 'name')\n",
      "(158368533, 'la', 'Vasingtonia', 'name')\n",
      "(158368533, 'lad', 'Washington, DC', 'name')\n",
      "(158368533, 'lb', 'Washington', 'name')\n",
      "(158368533, 'li', 'Washington D.C.', 'name')\n",
      "(158368533, 'lij', 'Washington D.C.', 'name')\n",
      "(158368533, 'ln', 'Washington', 'name')\n",
      "(158368533, 'lt', 'Vaingtonas', 'name')\n",
      "(158368533, 'lv', 'Vaingtona', 'name')\n",
      "(158368533, 'mg', 'Washington D.C', 'name')\n",
      "(158368533, 'mi', 'Takiw o Columbia', 'name')\n",
      "(158368533, 'mk', '', 'name')\n",
      "(158368533, 'ml', '', 'name')\n",
      "(158368533, 'mn', ' ', 'name')\n",
      "(158368533, 'mr', ', ..', 'name')\n",
      "(158368533, 'nds', 'Washington D.C.', 'name')\n",
      "(158368533, 'nl', 'Washington D.C.', 'name')\n",
      "(158368533, 'nov', 'Washington D.K.', 'name')\n",
      "(158368533, 'oc', 'Washington, DC', 'name')\n",
      "(158368533, 'os', '', 'name')\n",
      "(158368533, 'pap', 'Washington D.C.', 'name')\n",
      "(158368533, 'pdc', 'Washington D.C.', 'name')\n",
      "(158368533, 'pih', 'Woshingtun, D.K.', 'name')\n",
      "(158368533, 'pl', 'Waszyngton', 'name')\n",
      "(158368533, 'pms', 'Washington', 'name')\n",
      "(158368533, 'pnb', '  ', 'name')\n",
      "(158368533, 'ps', '  ', 'name')\n",
      "(158368533, 'rm', 'Washington D.C.', 'name')\n",
      "(158368533, 'ru', '', 'name')\n",
      "(158368533, 'rue', '', 'name')\n",
      "(158368533, 'sa', '  ', 'name')\n",
      "(158368533, 'sah', ',  ', 'name')\n",
      "(158368533, 'sc', 'Washington', 'name')\n",
      "(158368533, 'scn', 'Washington', 'name')\n",
      "(158368533, 'se', 'Washington D.C.', 'name')\n",
      "(158368533, 'sg', 'Washington D.C.', 'name')\n",
      "(158368533, 'sh', 'Washington D.C.', 'name')\n",
      "(158368533, 'sk', 'Washington D.C.', 'name')\n",
      "(158368533, 'so', 'Washington D.C', 'name')\n",
      "(158368533, 'sq', 'Uashington D.C.', 'name')\n",
      "(158368533, 'srn', 'Washington D.C.', 'name')\n",
      "(158368533, 'sv', 'Washington D.C.', 'name')\n",
      "(158368533, 'ta', ', . .', 'name')\n",
      "(158368533, 'te', ', ..', 'name')\n",
      "(158368533, 'tg', '  ', 'name')\n",
      "(158368533, 'th', '', 'name')\n",
      "(158368533, 'tk', 'Waington', 'name')\n",
      "(158368533, 'tok', 'ma tomo Sisi', 'name')\n",
      "(158368533, 'tpi', 'Wasington DC', 'name')\n",
      "(158368533, 'tt', '', 'name')\n",
      "(158368533, 'tw', 'Washington, D. C.', 'name')\n",
      "(158368533, 'ty', 'Washington', 'name')\n",
      "(158368533, 'ug', '', 'name')\n",
      "(158368533, 'uk', '', 'name')\n",
      "(158368533, 'ur', '  ', 'name')\n",
      "(158368533, 'uz', 'Vashington', 'name')\n",
      "(158368533, 'vec', 'Washington D.C.', 'name')\n",
      "(158368533, 'vep', 'Vaington', 'name')\n",
      "(158368533, 'vo', 'Washington', 'name')\n",
      "(158368533, 'xal', '', 'name')\n",
      "(158368533, 'xmf', '', 'name')\n",
      "(158368533, 'yi', '', 'name')\n",
      "(158368533, 'zh', '', 'name')\n",
      "(158368533, 'zh-yue', '', 'name')\n",
      "(158368533, 'old_name', 'District of Columbia', 'regular')\n",
      "(158368533, 'vi', 'Hoa Thnh n', 'old_name')\n",
      "(158368533, 'place', 'city', 'regular')\n",
      "(158368533, 'population', '672228', 'regular')\n",
      "(158368533, 'rank', '0', 'regular')\n",
      "(158368533, 'wikidata', 'Q61', 'regular')\n",
      "(158368533, 'wikipedia', 'en:Washington, D.C.', 'regular')\n"
     ]
    }
   ],
   "source": [
    "run_query ('SELECT * FROM nodes_tags WHERE id = 158368533') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After seeing all the tags, I know that the reason why this node have so many tags is that these tags describe Washington D.C. itself and its names in many languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Which ways have most/least nodes and how many nodes do they have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1860, 232054381)\n",
      "(1759, 289486048)\n",
      "(1657, 405489795)\n",
      "(1563, 42003302)\n",
      "(1463, 493749667)\n",
      "(1436, 232272021)\n",
      "(1247, 183205906)\n",
      "(946, 368672044)\n",
      "(912, 52302188)\n",
      "(853, 518015144)\n"
     ]
    }
   ],
   "source": [
    "run_query ('SELECT COUNT(*), id FROM ways_nodes GROUP BY id ORDER BY COUNT(*) DESC LIMIT 10') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 6051300)\n",
      "(2, 6051307)\n",
      "(2, 6051328)\n",
      "(2, 6051335)\n",
      "(2, 6051337)\n",
      "(2, 6051376)\n",
      "(2, 6051409)\n",
      "(2, 6051435)\n",
      "(2, 6051438)\n",
      "(2, 6051544)\n"
     ]
    }
   ],
   "source": [
    "run_query ('SELECT COUNT(*), id FROM ways_nodes GROUP BY id ORDER BY COUNT(*) LIMIT 10') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ways with most nodes have about 1000+ nodes. Each way has at least 2 nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Which way is the 'longest' way?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A interesting question comes into my mind: Which way is the 'longest' way? The 'longest' I define here is that the longest distance between the start point and end point of the way. The way with most nodes is probably not the longest way because we don't know neither whether the way is closed nor the straightness of the way. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to calculate the distance using the formula below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\sqrt[]{(lon_{end} - lon_{start})^2+(lat_{end} - lat_{start})^2}$$ ('lon' is longitude and 'lat' is latitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But sqlite do not support the calculation of square root. Instead, I use the formula below, just for comparison. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ (lon_{end} - lon_{start})^2+(lat_{end} - lat_{start})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my strategy of designing the query:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Select rows with position 0 (table2) and maximum position (table1) from ways_nodes and join them together on id.  \n",
    "   \n",
    "   \n",
    "'SELECT node_id_max, node_id_min, table1.id AS id  \n",
    "FROM   \n",
    "(SELECT node_id AS node_id_max, MAX(position), id FROM ways_nodes GROUP BY id) AS table1   \n",
    "JOIN   \n",
    "(SELECT node_id AS node_id_min, id FROM ways_nodes WHERE position = 0) AS table2  \n",
    "ON  \n",
    "table1.id = table2.id'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Find out open ways, not closed ways. Open ways may be roads, highways, and railways etc.. Closed ways usually are areas like parks, schools etc.. The start (nodes at position 0) and end nodes (nodes at maximum position) of open ways are different. Name the table with open ways as table3.\n",
    "  \n",
    "  \n",
    "'(SELECT node_id_max, node_id_min, table1.id AS id  \n",
    "FROM  \n",
    "(<font color=blue>SELECT node_id AS node_id_max, MAX(position), id FROM ways_nodes GROUP BY id</font>) AS <font color=blue>table1</font>   \n",
    "JOIN   \n",
    "(<font color=green>SELECT node_id AS node_id_min, id FROM ways_nodes WHERE position = 0</font>) AS <font color=green>table2</font>  \n",
    "ON  \n",
    "table1.id = table2.id  \n",
    "<font color=red>WHERE node_id_max != node_id_min</font>) AS table3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Use JOIN function to link two tables: table3 and nodes. To make start/end longitude and latitude in the same line with the corresponding ways_id.  \n",
    "  \n",
    "SELECT lon_start, lat_start, lon AS lon_end, lat AS lat_end, table4.ways_id AS ways_id   \n",
    "FROM  \n",
    "nodes  \n",
    "JOIN  \n",
    "(<font color=red>SELECT nodes.id, lon AS lon_start, lat AS lat_start, table3.node_id_min, table3.node_id_max, table3.id AS   ways_id  \n",
    "FROM  \n",
    "nodes  \n",
    "JOIN  \n",
    "table3  \n",
    "ON  \n",
    "nodes.id = table3.node_id_min</font>) AS <font color=red>table4</font>  \n",
    "ON\n",
    "nodes.id = table4.node_id_max  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Calulate the distance using the formula above and order by it.   \n",
    "  \n",
    "SELECT  \n",
    "(lon_end - lon_start)*(lon_end - lon_start)+(lat_end - lat_start)*(lat_end - lat_start) AS distance_square,  \n",
    "ways_id  \n",
    "FROM  \n",
    "table4  \n",
    "ORDER BY distance_square DESC  \n",
    "LIMIT 10  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is my full query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''\n",
    "SELECT\n",
    "(lon_end - lon_start)*(lon_end - lon_start)+(lat_end - lat_start)*(lat_end - lat_start) AS distance_square,\n",
    "ways_id\n",
    "FROM\n",
    "(SELECT lon_start, lat_start, lon AS lon_end, lat AS lat_end, table4.ways_id AS ways_id \n",
    "FROM\n",
    "nodes\n",
    "JOIN\n",
    "(SELECT nodes.id, lon AS lon_start, lat AS lat_start, table3.node_id_min, table3.node_id_max, table3.id AS ways_id\n",
    "FROM\n",
    "nodes\n",
    "JOIN\n",
    "(SELECT node_id_max, node_id_min, table1.id AS id\n",
    "FROM \n",
    "(SELECT node_id AS node_id_max, MAX(position), id FROM ways_nodes GROUP BY id) AS table1 \n",
    "JOIN \n",
    "(SELECT node_id AS node_id_min, id FROM ways_nodes WHERE position = 0) AS table2\n",
    "ON\n",
    "table1.id = table2.id\n",
    "WHERE node_id_max != node_id_min) AS table3\n",
    "ON\n",
    "nodes.id = table3.node_id_min) AS table4\n",
    "ON\n",
    "nodes.id = table4.node_id_max)\n",
    "ORDER BY distance_square DESC\n",
    "LIMIT 10 \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the TOP 10 longest ways with their id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.08060945860713437, 454552060)\n",
      "(0.07471173990690035, 518015144)\n",
      "(0.07464709465039931, 454552058)\n",
      "(0.05497556201770428, 454552038)\n",
      "(0.05031405611139642, 73533738)\n",
      "(0.04332474482018089, 454552046)\n",
      "(0.021600147350659692, 87759965)\n",
      "(0.015386612247890353, 368672044)\n",
      "(0.012504105768499724, 283869089)\n",
      "(0.011528489170249531, 59524015)\n"
     ]
    }
   ],
   "source": [
    "run_query (query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find what these ways are, I run another query to search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(518015144, 'source', 'NPS; Park Service Map; USGS NM', 'regular')\n",
      "(454552058, 'source', 'DCGIS; NPS; Park Service Map; USGS NM', 'regular')\n",
      "(454552038, 'leisure', 'park', 'regular')\n",
      "(454552038, 'source', 'DCGIS;NPS;Park Service Map;USGS NM', 'regular')\n",
      "(73533738, 'electrified', 'contact_line', 'regular')\n",
      "(73533738, 'frequency', '25', 'regular')\n",
      "(73533738, 'gauge', '1435', 'regular')\n",
      "(73533738, 'operator', 'Philadelphia, Baltimore and Washington Railroad', 'historic')\n",
      "(73533738, 'owner', 'Pennsylvania Railroad', 'historic')\n",
      "(73533738, 'name', 'Northeast Corridor', 'regular')\n",
      "(73533738, 'operator', 'Amtrak', 'regular')\n",
      "(73533738, 'railway', 'rail', 'regular')\n",
      "(73533738, 'source', 'USGS Ortho', 'regular')\n",
      "(73533738, 'usage', 'main', 'regular')\n",
      "(73533738, 'voltage', '12000', 'regular')\n",
      "(87759965, 'name', 'Lower Potomac River', 'regular')\n",
      "(87759965, 'source', 'USGS Ortho', 'regular')\n",
      "(87759965, 'waterway', 'river', 'regular')\n",
      "(87759965, 'wikidata', 'Q179444', 'regular')\n",
      "(368672044, 'leisure', 'park', 'regular')\n",
      "(368672044, 'source', 'USGS Ortho', 'regular')\n",
      "(283869089, 'route', 'ferry', 'regular')\n",
      "(59524015, 'dataset', 'MetroFullLn', 'dc-gis')\n",
      "(59524015, 'gis_id', 'Metro_004', 'dc-gis')\n",
      "(59524015, 'pubdate', '2007-04-05', 'dc-gis')\n",
      "(59524015, 'electrified', 'rail', 'regular')\n",
      "(59524015, 'frequency', '0', 'regular')\n",
      "(59524015, 'gauge', '1435', 'regular')\n",
      "(59524015, 'layer', '-3', 'regular')\n",
      "(59524015, 'name', 'Washington Metro - Red Line', 'regular')\n",
      "(59524015, 'operator', 'Washington Metropolitan Area Transit Authority', 'regular')\n",
      "(59524015, 'railway', 'subway', 'regular')\n",
      "(59524015, 'tracks', '2', 'regular')\n",
      "(59524015, 'tunnel', 'yes', 'regular')\n",
      "(59524015, 'voltage', '750', 'regular')\n"
     ]
    }
   ],
   "source": [
    "run_query ('''\n",
    "SELECT \n",
    "ways_tags.*\n",
    "FROM\n",
    "ways_tags \n",
    "JOIN\n",
    "(SELECT\n",
    "(lon_end - lon_start)*(lon_end - lon_start)+(lat_end - lat_start)*(lat_end - lat_start) AS distance_square,\n",
    "ways_id\n",
    "FROM\n",
    "(SELECT lon_start, lat_start, lon AS lon_end, lat AS lat_end, table4.ways_id AS ways_id \n",
    "FROM\n",
    "nodes\n",
    "JOIN\n",
    "(SELECT nodes.id, lon AS lon_start, lat AS lat_start, table3.node_id_min, table3.node_id_max, table3.id AS ways_id\n",
    "FROM\n",
    "nodes\n",
    "JOIN\n",
    "(SELECT node_id_max, node_id_min, table1.id AS id\n",
    "FROM \n",
    "(SELECT node_id AS node_id_max, MAX(position), id FROM ways_nodes GROUP BY id) AS table1 \n",
    "JOIN \n",
    "(SELECT node_id AS node_id_min, id FROM ways_nodes WHERE position = 0) AS table2\n",
    "ON\n",
    "table1.id = table2.id\n",
    "WHERE node_id_max != node_id_min) AS table3\n",
    "ON\n",
    "nodes.id = table3.node_id_min) AS table4\n",
    "ON\n",
    "nodes.id = table4.node_id_max)\n",
    "ORDER BY distance_square DESC\n",
    "LIMIT 10) AS table5\n",
    "ON \n",
    "ways_tags.id = table5.ways_id\n",
    "ORDER BY distance_square DESC\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all the TOP 10 longest ways have tags. For example, the most longest way (id 454552060) have no tags, neither do id 454552046. Some tags are meaningless. For example, id 518015144 and 454552058 each have only one tag: 'source', which makes people can't know what do these ways represent. Besides, some tags probably are wrong. For example, id 454552038 and 368672044 each represents a park, according to their tags. But all the ways list here are open ways, not closed ways, which means they cannot represent closed areas (According to https://wiki.openstreetmap.org/wiki/Way ). There are only 4 meaningful ways: id 73533738 is a railway line, id 87759965 is a river, id 283869089 is a ferry route, and id 59524015 is a subway line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3. Suggestion for improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put more effort in the data auditing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do suggest that the developer of OpenStreetMap hire more people to do data auditing because the data quality is not so good:  \n",
    "  \n",
    "  \n",
    "First, the format of street names and postcodes are not normalized. For street names, abbreviations and full names are both used, for example, 'NE' and 'Northeast'. For postcodes, five-digit codes are mixed with nine-digit codes. This may not be a big problem for human users, but not good for large-scale data processing by machine. They should make a standard for name and normalize all data.    \n",
    "\n",
    "Second, some attributes are wrong. For example, 'Canal Center Plaza' should not be a street name, '2005' should not be a postcode, and an open way should not represent an area. These wrong attributes will be misleading for map users.  \n",
    "  \n",
    "I know OpenStreetMap is free and non-profit, so it is very hard for them to hire more people to do auditing. But maybe they can learn from what reCAPTCHAs did: reCAPTCHAs replace previous random CAPTCHAs with pictures of illegible ancient books and let people all around the world do the artificial recognition of books while doing CAPTCHAs entering. So I suggest that OpenStreetMap can learn from that and make a rule: An user must audit some old data of an area before he submit his new data of the same area."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
